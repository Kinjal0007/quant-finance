# Worker Service

FastAPI-based microservice for processing financial modeling jobs asynchronously. Receives jobs via Pub/Sub, executes financial models, and stores results.

## ğŸš€ Features

- **Financial Models**: Monte Carlo, Markowitz, and Black-Scholes implementations
- **Asynchronous Processing**: Pub/Sub integration for job queuing
- **Data Ingestion**: EOD Historical Data and Twelve Data integration
- **Result Storage**: Cloud Storage for artifacts and BigQuery for metrics
- **Fixture Mode**: Demo data support for development

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Pub/Sub       â”‚    â”‚   Worker        â”‚    â”‚   Financial     â”‚
â”‚   (Job Queue)   â”‚â—„â”€â”€â–ºâ”‚   Service       â”‚â—„â”€â”€â–ºâ”‚   Models        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â”‚                       â–¼                       â”‚
         â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
         â”‚              â”‚   Data Sources  â”‚              â”‚
         â”‚              â”‚   (EODHD, 12D)  â”‚              â”‚
         â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
         â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Job Status    â”‚    â”‚   BigQuery      â”‚    â”‚   Cloud Storage â”‚
â”‚   Updates       â”‚    â”‚   (Prices)      â”‚    â”‚   (Artifacts)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
backend/worker/
â”œâ”€â”€ main.py                       # FastAPI application entry point
â”œâ”€â”€ models.py                     # Financial model implementations
â”œâ”€â”€ bq.py                         # BigQuery data loading and querying
â”œâ”€â”€ gcs.py                        # Cloud Storage operations
â”œâ”€â”€ demo_loader.py                # Fixture data loading for development
â”œâ”€â”€ ingestors/                    # Data ingestion modules
â”‚   â”œâ”€â”€ eodhd_ingestor.py        # EOD Historical Data integration
â”‚   â””â”€â”€ twelve_data_ingestor.py  # Twelve Data integration
â”œâ”€â”€ fixtures/                     # Demo data files
â”‚   â””â”€â”€ prices_demo.csv          # Sample price data for development
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ Dockerfile                    # Container configuration
â””â”€â”€ README.md                     # This file
```

## ğŸ¯ Core Features

### Financial Models

- **Monte Carlo Simulation**: Stock price simulation using Geometric Brownian Motion
- **Markowitz Portfolio Optimization**: Global minimum-variance portfolio optimization
- **Black-Scholes Option Pricing**: European option pricing with Greeks calculation

### Job Processing

- **Asynchronous Execution**: Non-blocking job processing
- **Progress Tracking**: Job status updates
- **Result Generation**: Metrics and visualization data
- **Error Handling**: Failure handling and recovery

### Data Management

- **Multi-Source Ingestion**: EOD Historical Data and Twelve Data integration
- **Data Standardization**: Unified OHLCV format
- **Historical Data**: End-of-day and intraday price data
- **Corporate Actions**: Dividends, splits, and mergers data

## ğŸ› ï¸ Tech Stack

- **Framework**: FastAPI with Python 3.11+
- **Data Processing**: Pandas, NumPy, SciPy, Scikit-learn
- **Cloud Integration**: BigQuery, Cloud Storage, Pub/Sub
- **Containerization**: Docker with Cloud Run deployment

## ğŸš€ Quick Start

### Prerequisites

- Python 3.11+
- Google Cloud SDK
- BigQuery and Cloud Storage access

### Setup

1. **Install dependencies**

```bash
cd backend/worker
pip install -r requirements.txt
```

2. **Environment variables**

```bash
# Create .env file
GCP_PROJECT=your-project-id
GCP_REGION=your-region
EODHD_API_KEY=your_eodhd_key
TWELVE_DATA_API_KEY=your_twelve_data_key
USE_FIXTURE=true  # For development without API keys
```

3. **Run the service**

```bash
python main.py
```

## ğŸ”§ Configuration

### Environment Variables

| Variable              | Description                   | Required                   |
| --------------------- | ----------------------------- | -------------------------- |
| `GCP_PROJECT`         | Google Cloud project ID       | Yes                        |
| `GCP_REGION`          | Google Cloud region           | Yes                        |
| `EODHD_API_KEY`       | EOD Historical Data API key   | No (if using fixture mode) |
| `TWELVE_DATA_API_KEY` | Twelve Data API key           | No (if using fixture mode) |
| `USE_FIXTURE`         | Use demo data for development | No (default: false)        |

### Fixture Mode

For development without vendor API keys, set `USE_FIXTURE=true`. This will use sample data from `fixtures/prices_demo.csv`.

## ğŸ“š API Endpoints

### Health Check

- `GET /health` - Service health status

### Job Processing

- Jobs are processed via Pub/Sub messages
- Results stored in BigQuery and Cloud Storage
- Status updates sent back to main API

## ğŸ§ª Development

### Running Locally

```bash
# With fixture mode (no API keys needed)
export USE_FIXTURE=true
python main.py

# With real API keys
export USE_FIXTURE=false
export EODHD_API_KEY=your_key
export TWELVE_DATA_API_KEY=your_key
python main.py
```

### Testing

```bash
# Run tests (when implemented)
python -m pytest

# Check code quality
python -m black . --line-length 88
python -m isort .
```

## ğŸš€ Deployment

### Docker

```bash
docker build -t quant-finance-worker .
docker run -p 8000:8000 quant-finance-worker
```

### Google Cloud Run

```bash
gcloud run deploy quant-finance-worker \
  --image gcr.io/PROJECT_ID/quant-finance-worker \
  --platform managed \
  --region REGION \
  --allow-unauthenticated
```

## ğŸ“Š Financial Models

### Monte Carlo Simulation

- **Purpose**: Stock price simulation and risk analysis
- **Parameters**: Initial price, drift, volatility, time steps, simulations
- **Output**: Price distribution, percentiles, risk metrics

### Markowitz Portfolio Optimization

- **Purpose**: Optimal portfolio allocation
- **Parameters**: Asset symbols, time period, risk tolerance
- **Output**: Optimal weights, expected return, volatility, Sharpe ratio

### Black-Scholes Option Pricing

- **Purpose**: European option valuation
- **Parameters**: Stock price, strike price, time to expiry, risk-free rate, volatility
- **Output**: Option price, Greeks (delta, gamma, theta, vega, rho)

## ğŸ” Troubleshooting

### Common Issues

1. **GCP Authentication**: Ensure service account has proper permissions
2. **BigQuery Access**: Check dataset and table permissions
3. **API Rate Limits**: Monitor vendor API usage
4. **Memory Issues**: Adjust Cloud Run memory allocation

### Logs

- Check Cloud Run logs for detailed error information
- Monitor Pub/Sub message processing
- Verify BigQuery and Cloud Storage operations

## ğŸ“š Documentation

- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [Google Cloud Pub/Sub](https://cloud.google.com/pubsub/docs)
- [BigQuery Python Client](https://googleapis.dev/python/bigquery/latest/index.html)
- [Cloud Storage Python Client](https://googleapis.dev/python/storage/latest/index.html)

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request
